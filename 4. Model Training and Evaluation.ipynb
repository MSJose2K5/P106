{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Part4_Solution.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"fm5CP0JFHOyg","colab_type":"text"},"source":["<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n","\n","<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n","        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n","    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n","        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">Deep Learning </span> for Satellite Image Classification</span> (Manning Publications)<br/>by <em>Daniel Buscombe</em></strong><br/><br/>\n","        <strong>> Chapter 4: Deliverable Solution </strong><br/>\n","    </p>   "]},{"cell_type":"markdown","metadata":{"id":"QGdtL0BpHS3k","colab_type":"text"},"source":["#### Preliminaries for Colab\n","\n","Like Part 3, below are some convenience functions for those working on Google Colab with a GPU runtime"]},{"cell_type":"code","metadata":{"id":"AhyLQfR6HS-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"107ec0df-97d2-4770-a53b-bbd8a7911376","executionInfo":{"status":"ok","timestamp":1572817125299,"user_tz":420,"elapsed":85568,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}}},"source":["colab = 0\n","#colab = 1\n","\n","if colab==1:\n","    %tensorflow_version 2.x\n","    #!pip install --default-timeout=1000 tensorflow-gpu==2.0   "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n","\u001b[K     |████████████████████████████████| 380.8MB 36kB/s \n","\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 6.3MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 36.6MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.33.6)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.8.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.17.3)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.1.7)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.12.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.2.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.11.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.15.0)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (41.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.16.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0) (2.8.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.2.7)\n","Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.2.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.7)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.21.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.24.3)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.6.3 which is incompatible.\u001b[0m\n","Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","tensorboard","tensorflow","tensorflow_core","tensorflow_estimator"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8_20Wje2bJI6","colab_type":"code","colab":{}},"source":["#%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-Tz07LIHfGu","colab_type":"text"},"source":["After restarting your runtime, make sure you have access to a GPU with Tensorflow 2"]},{"cell_type":"code","metadata":{"id":"svsb_z-QHfWO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3c2337d0-fce4-4799-aae4-5446a957a794","executionInfo":{"status":"ok","timestamp":1572818565700,"user_tz":420,"elapsed":2269,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}}},"source":["import tensorflow as tf\n","print(tf.__version__)\n","print(tf.test.is_gpu_available())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.0.0\n","False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6EyV9MHJH8Ww","colab_type":"text"},"source":["Convenience functions if you need to download example (minimal) imagery sets derived from NWPU and Sentinel-2 cloudless:\n"]},{"cell_type":"code","metadata":{"id":"KcQXFKiJH8hg","colab_type":"code","colab":{}},"source":["# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n","import requests\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = get_confirm_token(response)\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    save_response_content(response, destination)    \n","\n","def get_confirm_token(response):\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, destination):\n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in response.iter_content(CHUNK_SIZE):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)\n","\n","\n","#s2 cloudless imagery\n","file_id = '1iMfIjr_ul49Ghs2ewazjCt8HMPfhY47h'\n","destination = 's2cloudless_imagery.zip'\n","if colab==1:\n","    download_file_from_google_drive(file_id, destination)\n","\n","#s2 cloudless labels\n","file_id = '1c7MpwKVejoUuW9F2UaF_vps8Vq2RZRfR'\n","destination = 's2cloudless_label_imagery.zip'\n","if colab==1:\n","    download_file_from_google_drive(file_id, destination)\n","\n","\n","#nwpu imagery\n","file_id = '1gtuqy1VlU8-M5IEMnmiSuTlI5PxQPnGB'\n","destination = 'nwpu_images.zip'\n","if colab==1:\n","    download_file_from_google_drive(file_id, destination)\n","\n","#nwpu labels\n","file_id = '1W5LGbcYAcFbG5YjLgX_ekBn0u5Rno35x'\n","destination = 'nwpu_label_images.zip'\n","if colab==1:\n","    download_file_from_google_drive(file_id, destination)                        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLfCtu-tSzxE","colab_type":"code","colab":{}},"source":["import zipfile\n","def unzip(f):\n","    \"\"\"\n","    f = file to be unzipped\n","    \"\"\"    \n","    with zipfile.ZipFile(f, 'r') as zip_ref:\n","        zip_ref.extractall()\n","        \n","if colab==1:\n","    unzip('s2cloudless_imagery.zip')\n","    unzip('s2cloudless_label_imagery.zip')   \n","    unzip('nwpu_images.zip')\n","    unzip('nwpu_label_images.zip')       "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oQu4ce2HOym","colab_type":"text"},"source":["#### Setting up the model\n","\n","We'll pick up from the end of the Part 3 deliverable, where you should have test and train generator functions and hyperparameters set.\n","\n","You should have augmented images and associated labels for both sentinel2-cloudless and NWPU data\n","\n","Define the IOU function and Unet model:"]},{"cell_type":"code","metadata":{"id":"G3hJEjcPHOyo","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n","from tensorflow.keras.layers import Concatenate, Conv2DTranspose\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import json, os\n","from random import shuffle\n","from PIL import Image\n","import matplotlib\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRWqj3EVHOyv","colab_type":"code","colab":{}},"source":["def mean_iou(y_true, y_pred):\n","    yt0 = y_true[:,:,:,0]\n","    yp0 = tf.keras.backend.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n","    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n","    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n","    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n","    return iou\n","\n","def unet(sz = (512, 512, 3)):\n","    inputs = Input(sz)\n","    _ = inputs\n","  \n","    #down sampling \n","    f = 8\n","    layers = []\n","  \n","    for i in range(0, 6):\n","      _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","      _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","      layers.append(_)\n","      _ = MaxPooling2D() (_)\n","      f = f*2\n","    ff2 = 64 \n","  \n","    #bottleneck \n","    j = len(layers) - 1\n","    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","    _ = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_)\n","    _ = Concatenate(axis=3)([_, layers[j]])\n","    j = j -1 \n","  \n","    #upsampling \n","    for i in range(0, 5):\n","      ff2 = ff2//2\n","      f = f // 2 \n","      _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","      _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","      _ = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_)\n","      _ = Concatenate(axis=3)([_, layers[j]])\n","      j = j -1 \n","    \n","    #classification \n","    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n","    outputs = Conv2D(1, 1, activation='sigmoid') (_)\n","  \n","    #model creation \n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n","  \n","    return model  \n","\n","\n","model = unet()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3AW3Q2l8HOy1","colab_type":"text"},"source":["Create the class for training process plot, like shown in Part 4. One for each dataset. First, the augmented NWPU imagery"]},{"cell_type":"code","metadata":{"id":"UT_s6JJnHOy3","colab_type":"code","colab":{}},"source":["class PlotLearningNWPU(tf.keras.callbacks.Callback):\n","\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.losses = []\n","        self.val_losses = []\n","        self.acc = []\n","        self.val_acc = []\n","        self.logs = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.acc.append(logs.get('mean_iou'))\n","        self.val_acc.append(logs.get('val_mean_iou'))\n","        self.i += 1\n","        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n","        \n","        #choose a random test image and preprocess\n","        path = np.random.choice(test_filesNWPU)\n","        infile = f'nwpu_images/data/{path}'\n","        raw = Image.open(infile)\n","        raw = np.array(raw.resize((512, 512)))/255.\n","        raw = raw[:,:,0:3]\n","        \n","        #predict the mask \n","        pred = 255*model.predict(np.expand_dims(raw, 0)).squeeze()\n","        print(np.max(pred))\n","                \n","        #mask post-processing \n","        msk  = (pred>60).astype('int') #100       \n","        msk = np.stack((msk,)*3, axis=-1)\n","        \n","        #show the mask and the segmented image \n","        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n","        plt.axis('off')\n","        plt.imshow(combined)\n","        plt.show()\n","\n","def build_callbacksNWPU():\n","        checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='nwpu_unet.h5', verbose=0, save_best_only=True, save_weights_only=True)\n","        callbacks = [checkpointer, PlotLearningNWPU()]\n","        return callbacks"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srrx3NT8HOy8","colab_type":"text"},"source":["and a separate one for the S2 imagery"]},{"cell_type":"code","metadata":{"id":"QFXTQQ4iHOy9","colab_type":"code","colab":{}},"source":["class PlotLearningS2(tf.keras.callbacks.Callback):\n","\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.losses = []\n","        self.val_losses = []\n","        self.acc = []\n","        self.val_acc = []\n","        self.logs = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.acc.append(logs.get('mean_iou'))\n","        self.val_acc.append(logs.get('val_mean_iou'))\n","        self.i += 1\n","        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n","        \n","        #choose a random test image and preprocess\n","        path = np.random.choice(test_filesS2)\n","        infile = f's2cloudless_imagery/data/{path}'\n","        raw = Image.open(infile)\n","        raw = np.array(raw.resize((512, 512)))/255.\n","        raw = raw[:,:,0:3]\n","        \n","        #predict the mask \n","        pred = 255*model.predict(np.expand_dims(raw, 0)).squeeze()\n","        print(np.max(pred))\n","                \n","        #mask post-processing \n","        msk  = (pred>60).astype('int') #100       \n","        msk = np.stack((msk,)*3, axis=-1)\n","        \n","        #show the mask and the segmented image \n","        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n","        plt.axis('off')\n","        plt.imshow(combined)\n","        plt.show()\n","\n","def build_callbacksS2():\n","        checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='s2cloudless_unet.h5', verbose=0, save_best_only=True, save_weights_only=True)\n","        callbacks = [checkpointer, PlotLearningS2()]\n","        return callbacks"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2HUDb52iHOy_","colab_type":"text"},"source":["Define image generator files for each data set"]},{"cell_type":"code","metadata":{"id":"VcCCNzRFHOzA","colab_type":"code","colab":{}},"source":["def image_batch_generatorS2(files, batch_size = 32, sz = (512, 512)):\n","  \n","  while True: # this is here because it will be called repeatedly by the training function\n","    \n","    #extract a random subset of files of length \"batch_size\"\n","    batch = np.random.choice(files, size = batch_size)    \n","    \n","    #variables for collecting batches of inputs (x) and outputs (y)\n","    batch_x = []\n","    batch_y = []\n","    \n","    #cycle through each image in the batch\n","    for f in batch:\n","\n","        #preprocess the raw images \n","        rawfile = f's2cloudless_imagery/data/{f}'\n","        raw = Image.open(rawfile)\n","        raw = raw.resize(sz)\n","        raw = np.array(raw)\n","\n","        #check the number of channels because some of the images are RGBA or GRAY\n","        if len(raw.shape) == 2:\n","            raw = np.stack((raw,)*3, axis=-1)\n","\n","        else:\n","            raw = raw[:,:,0:3]\n","            \n","        #get the image dimensions, find the min dimension, then square the image off    \n","        nx, ny, nz = np.shape(raw)\n","        n = np.minimum(nx,ny)\n","        raw = raw[:n,:n,:] \n","            \n","        batch_x.append(raw)\n","        \n","        #get the masks. \n","        maskfile = rawfile.replace('s2cloudless_imagery','s2cloudless_label_imagery')+'_mask.jpg'\n","        mask = Image.open(maskfile)\n","        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n","        mask = np.max(np.array(mask.resize(sz)),axis=2)\n","        # water pixels are always greater than 100\n","        mask = (mask>100).astype('int')\n","        \n","        mask = mask[:n,:n]\n","\n","        batch_y.append(mask)\n","\n","    #preprocess a batch of images and masks \n","    batch_x = np.array(batch_x)/255. #divide image by 255 to normalize\n","    batch_y = np.array(batch_y)\n","    batch_y = np.expand_dims(batch_y,3) #add singleton dimension to batch_y\n","\n","    yield (batch_x, batch_y) #yield both the image and the label together"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DCiaTEWHOzD","colab_type":"code","colab":{}},"source":["def image_batch_generatorNWPU(files, batch_size = 32, sz = (512, 512)):\n","  \n","  while True: # this is here because it will be called repeatedly by the training function\n","    \n","    #extract a random subset of files of length \"batch_size\"\n","    batch = np.random.choice(files, size = batch_size)    \n","    \n","    #variables for collecting batches of inputs (x) and outputs (y)\n","    batch_x = []\n","    batch_y = []\n","    \n","    #cycle through each image in the batch\n","    for f in batch:\n","\n","        #preprocess the raw images \n","        rawfile = f'nwpu_images/data/{f}'\n","        raw = Image.open(rawfile)\n","        raw = raw.resize(sz)\n","        raw = np.array(raw)\n","\n","        #check the number of channels because some of the images are RGBA or GRAY\n","        if len(raw.shape) == 2:\n","            raw = np.stack((raw,)*3, axis=-1)\n","\n","        else:\n","            raw = raw[:,:,0:3]\n","            \n","        #get the image dimensions, find the min dimension, then square the image off    \n","        nx, ny, nz = np.shape(raw)\n","        n = np.minimum(nx,ny)\n","        raw = raw[:n,:n,:] \n","            \n","        batch_x.append(raw)\n","        \n","        #get the masks. \n","        maskfile = rawfile.replace('nwpu_images','nwpu_label_images')+'_mask.jpg'\n","        mask = Image.open(maskfile)\n","        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n","        mask = np.max(np.array(mask.resize(sz)),axis=2)\n","        # water pixels are always greater than 100\n","        mask = (mask>200).astype('int')\n","        \n","        mask = mask[:n,:n]\n","\n","        batch_y.append(mask)\n","\n","    #preprocess a batch of images and masks \n","    batch_x = np.array(batch_x)/255. #divide image by 255 to normalize\n","    batch_y = np.array(batch_y)\n","    batch_y = np.expand_dims(batch_y,3) #add singleton dimension to batch_y\n","\n","    yield (batch_x, batch_y) #yield both the image and the label together"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOAISPpTHOzF","colab_type":"text"},"source":["Create two models, one for each data set"]},{"cell_type":"code","metadata":{"id":"nYz_hO3tHOzG","colab_type":"code","colab":{}},"source":["modelNWPU = unet()\n","modelS2 = unet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"an_9Qsx3HOzI","colab_type":"code","colab":{}},"source":["batch_size = 8\n","\n","prop_train = 0.6"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pl2867qHOzL","colab_type":"text"},"source":["#### Sentinel2-cloudless (\"S2\") imagery\n","\n","Define the test and train steps like in Part 4 and run the model training"]},{"cell_type":"code","metadata":{"id":"4F4tlYzNHOzM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b930711c-a7ea-4a4e-e794-9a47dc551617","executionInfo":{"status":"ok","timestamp":1572818675294,"user_tz":420,"elapsed":350,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}}},"source":["all_files = os.listdir('s2cloudless_imagery/data')\n","shuffle(all_files)\n","\n","split = int(prop_train * len(all_files))\n","\n","#split into training and testing\n","train_filesS2 = all_files[0:split]\n","test_filesS2  = all_files[split:]\n","\n","train_stepsS2 = len(train_filesS2) //batch_size\n","test_stepsS2 = len(test_filesS2) //batch_size\n","\n","print(train_stepsS2)\n","print(test_stepsS2)\n","\n","train_generatorS2 = image_batch_generatorS2(train_filesS2, batch_size = batch_size)\n","test_generatorS2  = image_batch_generatorS2(test_filesS2, batch_size = batch_size)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["3\n","2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYiQ3_R4HOzO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1h2bRuhHgrHd7N5-Eb72oClsd2UcuQcys"},"outputId":"7f7d13ea-a064-4ba3-e232-b27ff226090f","executionInfo":{"status":"error","timestamp":1572823394044,"user_tz":420,"elapsed":4717672,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}}},"source":["historyS2 = model.fit_generator(train_generatorS2, \n","                    epochs = 100, steps_per_epoch = train_stepsS2,\n","                    validation_data = test_generatorS2, validation_steps = test_stepsS2,\n","                    callbacks = build_callbacksS2(), verbose = 0,\n","                    use_multiprocessing=True)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"E1GieTlEHOzR","colab_type":"text"},"source":["#### NWPU imagery\n","\n","Define the test and train steps like in Part 4 and run the model training"]},{"cell_type":"code","metadata":{"id":"bVEmxgfyHOzR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ef04c1f0-0249-48ca-ff63-9e318144750c","executionInfo":{"status":"ok","timestamp":1572823394048,"user_tz":420,"elapsed":347,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}}},"source":["all_files = os.listdir('nwpu_images/data')\n","shuffle(all_files)\n","\n","split = int(prop_train * len(all_files))\n","\n","#split into training and testing\n","train_filesNWPU = all_files[0:split]\n","test_filesNWPU  = all_files[split:]\n","\n","train_stepsNWPU = len(train_filesNWPU) //batch_size\n","test_stepsNWPU = len(test_filesNWPU) //batch_size\n","\n","print(train_stepsNWPU)\n","print(test_stepsNWPU)\n","\n","train_generatorNWPU = image_batch_generatorNWPU(train_filesNWPU, batch_size = batch_size)\n","test_generatorNWPU  = image_batch_generatorNWPU(test_filesNWPU, batch_size = batch_size)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["42\n","28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n74PbsRoHOzU","colab_type":"code","colab":{}},"source":["historyNWPU = model.fit_generator(train_generatorNWPU, \n","                    epochs = 100, steps_per_epoch = train_stepsNWPU,\n","                    validation_data = test_generatorNWPU, validation_steps = test_stepsNWPU,\n","                    callbacks = build_callbacksNWPU(), verbose = 0,\n","                    use_multiprocessing=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0IiMsrgHOzW","colab_type":"code","colab":{}},"source":["# summarize history for iou\n","plt.figure(figsize=(10,10))\n","plt.subplot(121)\n","plt.plot(historyS2.history['mean_iou'],'k',lw=1)\n","plt.plot(historyS2.history['val_mean_iou'],'r',lw=1)\n","plt.ylim(0,1)\n","plt.axhline(y=0.85)\n","plt.title('S2 model IoU')\n","plt.ylabel('IoU')\n","plt.xlabel('Epoch number')\n","plt.legend(['train', 'test'], loc='upper left')\n","\n","plt.subplot(122)\n","plt.plot(historyNWPU.history['mean_iou'],'k',lw=1)\n","plt.plot(historyNWPU.history['val_mean_iou'],'r',lw=1)\n","plt.title('NWPU model IoU')\n","plt.ylim(0,1)\n","plt.axhline(y=0.85)\n","plt.ylabel('IoU')\n","plt.xlabel('Epoch number')\n","plt.legend(['train', 'test'], loc='upper left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"untfGgwQHOzZ","colab_type":"text"},"source":["#### Test NWPU model on S2 imagery\n","\n","First, set up a new generator function to generate batches of S2 augmented imagery and associated labels. Then, define a function that will use the model (trained on NWPU imagery) to estimate the binary semantic segmentation mask for 100 images. Finally, we'll look at the mean IOU score, and their distribution"]},{"cell_type":"code","metadata":{"id":"AITDRaqXHOzZ","colab_type":"code","colab":{}},"source":["# rerun the generator function to start with a fresh set from the beginning of the list\n","test_generatorS2  = image_batch_generatorS2(test_filesS2, batch_size = batch_size)\n","\n","# we need to change the IOU function a little because the inputs are slightly different shapes than used in the training\n","def mean_iou(y_true, y_pred):\n","    yt0 = y_true.squeeze()\n","    yp0 = tf.keras.backend.cast(y_pred.squeeze() > 0.5, 'float32')\n","    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n","    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n","    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n","    return iou\n","\n","# a function for getting an estimated water mask from an input image, and IOU score evaluated against the real mask\n","def get_pred(x, y):\n","    #predict the mask \n","    pred = model.predict(np.expand_dims(x, 0))\n","    \n","    #mask post-processing \n","    msk  = pred.squeeze()\n","    # binarize\n","    msk[msk >= 0.5] = 1 \n","    msk[msk < 0.5] = 0\n","    # return the prediction and the IOU score of the prediction\n","    return msk, mean_iou(y, msk)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5tgLRVZHOzc","colab_type":"text"},"source":["Let's see how this will work:"]},{"cell_type":"code","metadata":{"id":"h1NTxGgYHOzd","colab_type":"code","colab":{}},"source":["#get a batch of S2 imagery and labels\n","x, y = next(test_generatorS2) \n","#get the predicted mask and iou score for the first\n","ypred, iou = get_pred(x[0], y[0]) \n","\n","#make a plot side-by-side of label ...\n","plt.subplot(121)\n","plt.imshow(x[0])\n","plt.imshow(y[0].squeeze(), alpha=0.5, cmap='gray')\n","plt.axis('off')\n","\n","# ... and estimated label\n","plt.subplot(122)\n","plt.imshow(x[0])\n","plt.imshow(ypred.squeeze(), alpha=0.5, cmap='gray')\n","plt.title(str(iou.numpy())[:4])\n","plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P54JvoPPHOzf","colab_type":"code","colab":{}},"source":["IOU = [] #initialize list\n","counter = 0 #initialize counter\n","while counter < 100: # compare 100 images\n","    x, y = next(test_generatorS2)\n","    ypred, iou = get_pred(x[0], y[0])\n","    IOU.append(iou) #update list\n","\n","    if counter % 5 == 0: #print every 5th comparison\n","        plt.figure(figsize=(4,6))\n","        plt.subplot(121)\n","        plt.imshow(x[0])\n","        plt.imshow(y[0].squeeze(), alpha=0.5, cmap='gray')\n","        plt.axis('off')\n","\n","        plt.subplot(122)\n","        plt.imshow(x[0])\n","        plt.imshow(ypred.squeeze(), alpha=0.5, cmap='gray')\n","        plt.title(str(iou.numpy())[:4])\n","        plt.axis('off')\n","        print(counter)  \n","        \n","    counter += 1 #update counter"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvkrQWTCHOzi","colab_type":"text"},"source":["Print the mean IOU score to screen and make a boxplot of the distribution of IOU scores"]},{"cell_type":"code","metadata":{"id":"Uji8EEV8HOzj","colab_type":"code","colab":{}},"source":["print(np.mean(IOU))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rmombe5IHOzn","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","fliers = dict(markerfacecolor='g', marker='p')\n","plt.figure(figsize=(8,4))\n","plt.boxplot(IOU, flierprops=fliers, vert=False, whis=0.75)\n","plt.xlabel('IOU scores')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zLwpFFshHOzr","colab_type":"text"},"source":["This baseline comparison isn't brilliant but it is pretty good considering it hasn't yet been optimized AND it was built on a completely different set of images (NWPU). In deep learning, this concept of training a model on one set of imagery and applying to another, is called `transfer learning` and is very common in modern machine learning workflows.\n","\n","We'll see in the final part many strategies for improving this accuracy. This distribution of IOU scores is the baseline against which we will improve upon"]},{"cell_type":"code","metadata":{"id":"1YNFqYAnHOzr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">Deep Learning </span> for Satellite Image Classification</span> (Manning Publications)<br/>by <em>Daniel Buscombe</em></strong><br/><br/>\n",
    "        <strong>> Chapter 3: Deliverable Solution </strong><br/>\n",
    "    </p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and test if Tensorflow sees an available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from random import shuffle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import json, os, glob\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the unzip function from Part 2 to unzip the imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_nwpu(f):\n",
    "    \"\"\"\n",
    "    f = file to be unzipped\n",
    "    \"\"\"    \n",
    "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "        \n",
    "unzip_nwpu('NWPU_images.zip')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same workflow as in Part 2 to delete folders of non-lake imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('images','nwpu_images')\n",
    "subdirecs = [x[0] for x in os.walk('nwpu_images')][1:]\n",
    "to_delete = [s for s in subdirecs if 'lake' not in s]\n",
    "for k in to_delete:\n",
    "    shutil.rmtree(k, ignore_errors=True) \n",
    "os.rename('nwpu_images'+os.sep+'lake','nwpu_images'+os.sep+'data')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make directories for NWPU label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('nwpu_label_images')\n",
    "os.mkdir('nwpu_label_images'+os.sep+'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets the X,Y polygon coordinates, creates a mask, and saves the mask to file. The function is composed mostly of commands shown in the Part 2 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    X = []; Y = [] #pre-allocate lists to fill in a for loop\n",
    "    for k in data['regions']: #cycle through each polygon\n",
    "        # get the x and y points from the dictionary\n",
    "        X.append(data['regions'][k]['shape_attributes']['all_points_x'])\n",
    "        Y.append(data['regions'][k]['shape_attributes']['all_points_y'])\n",
    "    return Y,X #image coordinates are flipped relative to json coordinates\n",
    "\n",
    "\n",
    "def write_mask(data, images, all_images, i):\n",
    "    X, Y = get_data(data[images[i]])\n",
    "    \n",
    "    # get the dimensions of the image\n",
    "    nx, ny, nz = np.shape(all_images[i])\n",
    "    mask = np.zeros((ny,nx))\n",
    "    \n",
    "    for x,y in zip(X,Y):\n",
    "        # the ImageDraw.Draw().polygon function we will use to create the mask\n",
    "        # requires the x's and y's are interweaved, which is what the following\n",
    "        # one-liner does    \n",
    "        polygon = np.vstack((x,y)).reshape((-1,),order='F').tolist()\n",
    "        \n",
    "        # create a mask image of the right size and infill according to the polygon\n",
    "        if nx>ny:\n",
    "            x,y = y,x \n",
    "            img = Image.new('L', (ny, nx), 0)\n",
    "        elif ny>nx:\n",
    "            x,y = y,x \n",
    "            img = Image.new('L', (ny, nx), 0)            \n",
    "        else:\n",
    "            img = Image.new('L', (nx, ny), 0)\n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "        # turn into a numpy array\n",
    "        m = np.flipud(np.rot90(np.array(img)))\n",
    "        try:\n",
    "            mask = mask + m\n",
    "        except:\n",
    "            mask = mask + m.T\n",
    "    matplotlib.image.imsave('nwpu_label_images'+os.sep+'data'+os.sep+images[i]+\"_mask.jpg\", mask.astype('uint8'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and merge the three VGG-JSON labels files and extract the list of sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "json_file = '..'+os.sep+'2_Data'+os.sep+'nwpu_labels'+os.sep+'nwpu_lakes_30samples.json'\n",
    "data.append(json.load(open(json_file)))\n",
    "json_file = '..'+os.sep+'2_Data'+os.sep+'nwpu_labels'+os.sep+'nwpu_lakes_20samplesA.json'\n",
    "data.append(json.load(open(json_file)))\n",
    "json_file = '..'+os.sep+'2_Data'+os.sep+'nwpu_labels'+os.sep+'nwpu_lakes_20samplesB.json'\n",
    "data.append(json.load(open(json_file)))\n",
    "\n",
    "data_merged = {}\n",
    "for d in data:\n",
    "    data_merged.update(d)\n",
    "\n",
    "images = sorted(data_merged.keys())\n",
    "print(images)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the image samples into an array, like in the Part 2 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "all_images = []\n",
    "for image in images:\n",
    "    with rasterio.open('nwpu_images'+os.sep+'data'+os.sep+image) as dataset:\n",
    "        all_images.append(dataset.read().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call ```write mask``` to write the image mask for each image sample, according to the information in ```data```, the json label structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    write_mask(data_merged, images, all_images, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same image batch generator we used in Part 3 to generate batches of labels and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_batch_generator(files, batch_size = 32, sz = (512, 512)):\n",
    "  \n",
    "  while True: # this is here because it will be called repeatedly by the training function\n",
    "    \n",
    "    #extract a random subset of files of length \"batch_size\"\n",
    "    batch = np.random.choice(files, size = batch_size)    \n",
    "    \n",
    "    #variables for collecting batches of inputs (x) and outputs (y)\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    #cycle through each image in the batch\n",
    "    for f in batch:\n",
    "\n",
    "        #preprocess the raw images \n",
    "        rawfile = f'nwpu_images/data/{f}'\n",
    "        raw = Image.open(rawfile)\n",
    "        raw = raw.resize(sz)\n",
    "        raw = np.array(raw)\n",
    "\n",
    "        #check the number of channels because some of the images are RGBA or GRAY\n",
    "        if len(raw.shape) == 2:\n",
    "            raw = np.stack((raw,)*3, axis=-1)\n",
    "        else:\n",
    "            raw = raw[:,:,0:3]\n",
    "            \n",
    "        #get the image dimensions, find the min dimension, then square the image off    \n",
    "        nx, ny, nz = np.shape(raw)\n",
    "        n = np.minimum(nx,ny)\n",
    "        raw = raw[:n,:n,:] \n",
    "            \n",
    "        batch_x.append(raw)\n",
    "        \n",
    "        #get the masks. \n",
    "        maskfile = rawfile.replace('nwpu_images','nwpu_label_images')+'_mask.jpg'\n",
    "        mask = Image.open(maskfile)\n",
    "        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n",
    "        mask = np.max(np.array(mask.resize(sz)),axis=2)\n",
    "        # water pixels are always greater than 100\n",
    "        mask = (mask>100).astype('int')\n",
    "        \n",
    "        mask = mask[:n,:n]\n",
    "\n",
    "        batch_y.append(mask)\n",
    "\n",
    "    #preprocess a batch of images and masks \n",
    "    batch_x = np.array(batch_x)/255. #divide image by 255 to normalize\n",
    "    batch_y = np.array(batch_y)\n",
    "    batch_y = np.expand_dims(batch_y,3) #add singleton dimension to batch_y\n",
    "\n",
    "    yield (batch_x, batch_y) #yield both the image and t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Part 3, specify a batch size, proportion to use for training, and make test and train generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "prop_train = 0.5\n",
    "\n",
    "split = int(prop_train * len(images))\n",
    "\n",
    "#split into training and testing\n",
    "train_files = images[0:split]\n",
    "test_files  = images[split:]\n",
    "\n",
    "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
    "test_generator  = image_batch_generator(test_files, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using augmented NWPU imagery\n",
    "\n",
    "Set up mask and image generators like in Part 3, and merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "img_generator = train_datagen.flow_from_directory(\n",
    "        'nwpu_images',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, seed=42, shuffle=False)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,    \n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        rotation_range=90,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "mask_generator = test_datagen.flow_from_directory(\n",
    "        'nwpu_label_images',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, seed=42, shuffle=False)\n",
    "\n",
    "train_generator = (pair for pair in zip(img_generator, mask_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that worked by using the `next` command to get a random sample, then plot it like in Part 3 to see if the augmentation worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_generator)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow((x[0]).astype('uint8'), cmap='gray')\n",
    "plt.imshow(np.max(y[0], axis=2)/255, cmap='gray', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate 500 augmented files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aug_files = 500\n",
    "\n",
    "# merge the two generators together, scaling each image so it is scaled 0 -- 1\n",
    "train_generator2 = (tuple(np.array(pair, dtype='float64')/255) for pair in zip(img_generator, mask_generator))\n",
    "\n",
    "# create label files\n",
    "counter = 0\n",
    "while counter<n_aug_files:\n",
    "    x, y = next(train_generator2)\n",
    "    matplotlib.image.imsave('nwpu_label_images'+os.sep+'data'+os.sep+\"augimage00\"+str(counter)+\".jpg_mask.jpg\", np.squeeze(y[0])) \n",
    "    matplotlib.image.imsave('nwpu_images'+os.sep+'data'+os.sep+\"augimage00\"+str(counter)+\".jpg\", np.squeeze(x[0]))    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
